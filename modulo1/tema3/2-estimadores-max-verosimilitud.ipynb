{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimadores de máxima verosimilitud\n",
    "\n",
    "![MLE](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/MLfunctionbinomial-en.svg/600px-MLfunctionbinomial-en.svg.png)\n",
    "\n",
    "> La estimación por máxima verosimilitud (maximum likelihood estimation - MLE) es uno de los métodos más utilizados para estimar los parámetros de un modelo probabilístico.\n",
    "\n",
    "> La idea básica, es elegir los parámetros que maximizan la función de verosimilitud. Intuitivamente, esto corresponde a elegir los parámetros que maximizan la probabilidad de los datos observados.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Comprender el principio de máxima verosimilitud a través de ejemplos básicos.\n",
    "> - Estimar los parámetros de algunas distribuciones comunes usando el principio de máxima verosimilitud.\n",
    "> - Entender las limitaciones básicas de los estimadores de máxima verosimilitud.\n",
    "\n",
    "Referencia:\n",
    "\n",
    "- http://www.cs.toronto.edu/~rgrosse/csc321/probabilistic_models.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introducción\n",
    "\n",
    "Suponga que tenemos una secuencia de datos $x_1, \\dots, x_n$ que sabemos que provienen de una distribución exponencial. La pregunta es: **¿De cuál distribución exponencial vienen los datos?**\n",
    "\n",
    "Ya hemos hablado de algunas distribuciones, como la binomial, la exponencial, la normal, etcétera. De hecho, lo que llamamos distribución exponencial $\\text{Exponential}(\\lambda)$ no es una sola distribución sino una familia de distribucions parametrizadas por el parámetro $\\lambda$.\n",
    "\n",
    "Es decir, cada valor de $\\lambda$ define una distribución dentro de la familia, con pdf $p(x) = \\lambda e^{-\\lambda x}$. Esto se extiende a las demás distribuciones que hemos estudiado.\n",
    "\n",
    "Ahora, es común que nos enfrentemos a la situación de tener datos aleatorios de los que sabemos (o creemos) que provienen de una distribución paramétrica, cuyos parámetros desconocemos. En este caso queremos utilizar los datos para estimar (o inferir) el valor del (de los) parámetro(s).\n",
    "\n",
    "En clases anteriores, nos concentrábamos en obtener la probabilidad de obtener cierto dato a partir de algún modelo paramétrico con parámetros conocidos. Ahora, en estadística inferencial, le damos la vuelta: estimaremos la probabilidad de los parámetros dados un modelo y datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Principios básicos\n",
    "\n",
    "### 1.1. Principio de máxima verosimilitud\n",
    "\n",
    "**Retomamos el ejemplo de la moneda**.\n",
    "\n",
    "De clases pasadas, sabemos que el experimento de tirar la moneda $n$ veces y contar el número de caras, sigue una distribución $\\text{Binomial}(n,\\theta)$, con pmf\n",
    "\n",
    "$$\n",
    "p(a) = \\left(\\begin{array}{c}n \\\\ a \\end{array}\\right) \\theta^a (1 - \\theta)^{n-a}\n",
    "$$\n",
    "\n",
    "donde $a$ es el número de caras.\n",
    "\n",
    "En un ejemplo concreto, supongamos que se tiró la moneda 100 veces y contamos 55 caras. Por tanto, sabemos que\n",
    "\n",
    "$$\n",
    "p(55) = \\left(\\begin{array}{c}100 \\\\ 55\\end{array}\\right) \\theta^{55}(1 - \\theta)^{45}\n",
    "$$\n",
    "\n",
    "Observamos que la probabilidad de obtener 55 caras depende del valor de $\\theta$, por lo que es usual incluir esto con la notación de probabilidad condicional:\n",
    "\n",
    "$$\n",
    "p(55 | \\theta) = \\left(\\begin{array}{c}100 \\\\ 55\\end{array}\\right) \\theta^{55}(1 - \\theta)^{45}\n",
    "$$\n",
    "\n",
    "Lo anterior, lo podemos leer como: \"la probabilidad de obtener 55 caras dado que la probabilidad de cara en un tiro individual es $\\theta$\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos términos estándar que usamos en estadística:\n",
    "\n",
    "- **Experimento**: Tirar la moneda 100 veces y contar el número de caras.\n",
    "\n",
    "- **Datos**: Los datos son el resultado del experimento. En este caso son las 55 caras.\n",
    "\n",
    "- **Parámetros de interés**: Estamos interesados en conocer el valor del parámetro $\\theta$.\n",
    "\n",
    "- **(Función de) Verosimilitud**: Es la función $p(datos | parámetros)$. Notemos que es una función tanto de los datos, como de los parámetros. En nuestro caso es\n",
    "  $$\n",
    "  p(55 | \\theta) = \\left(\\begin{array}{c}100 \\\\ 55\\end{array}\\right) \\theta^{55}(1 - \\theta)^{45}.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, una idea razonable es encontrar los parámetros de modo que la Verosimilitud sea máxima (que se maximice la probabilidad de los datos observados).\n",
    "\n",
    "**Definición.** Dado un conjunto de datos, el estimador de máxima verosimilitud (MLE por sus siglas en inglés) para los parámetros, son los valores de los parámetros que maximizan la verosimilitud $p(datos | parámetros)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:**\n",
    "\n",
    "Para el problema en cuestión, queremos maximizar la versolimilitud \n",
    "\n",
    "$$\n",
    "p(55 | \\theta) = \\left(\\begin{array}{c}100 \\\\ 55\\end{array}\\right) \\theta^{55}(1 - \\theta)^{45}.\n",
    "$$\n",
    "\n",
    "Para esto usamos nociones de cálculo:\n",
    "\n",
    "<details>\n",
    "<summary>Descubrir</summary>\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\theta} p(55 | \\theta) = \\left(\\begin{array}{c}100 \\\\ 55\\end{array}\\right) \\left(55\\theta^{54}(1 - \\theta)^{45} - 45\\theta^{55}(1 - \\theta)^{44}\\right)\n",
    "$$\n",
    "\n",
    "Igualando a cero:\n",
    "\n",
    "$$\n",
    "\\begin{align} \\nonumber\n",
    "55\\theta^{54}(1 - \\theta)^{45} = 45\\theta^{55}(1 - \\theta)^{44} \\\\ \\nonumber\n",
    "55(1 - \\theta) = 45\\theta \\\\ \\nonumber\n",
    "55 = 100 \\theta\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Por lo que el MLE es $\\hat{\\theta} = \\frac{55}{100}$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentarios:\n",
    "\n",
    "1. Esto coincide con la intuición. El MLE para $\\theta$ resulta ser la fracción de caras que tenemos en nuestros datos.\n",
    "\n",
    "2. Para verificar que lo anterior es un máximo, podemos aplicar un criterio de segunda derivada. Otra opción, dado que tenemos un problema en un dominio cerrado $0 \\leq \\theta \\leq 1$, podemos evaluar en los extremos:\n",
    "   - $p(55 | \\theta=0) = p(55 | \\theta=1) = 0$\n",
    "   \n",
    "   y en el punto crítico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librería math (función math.comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos en el punto crítico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto concluimos que el único máximo es el que encontramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como luce la función de verosimilitud para casos como el de la moneda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos numpy\n",
    "\n",
    "# Importamos matplotlib.pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la función de verosimilitud con los datos del ejemplo\n",
    "# Parámetros - 100 tiros - 55 caras\n",
    "\n",
    "# Función de verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximamos el valor máximo de la verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujamos la función de verosimilitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pasaría en un caso de 1000 tiros con 550 caras?\n",
    "\n",
    "Veamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la función de verosimilitud con los datos del ejemplo\n",
    "# Parámetros - 1000 tiros - 550 caras\n",
    "\n",
    "# Función de verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximamos el valor máximo de la verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujamos las funcines de verosimilitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el MLE en ambos casos es el mismo, porque\n",
    "\n",
    "$$\n",
    "\\frac{550}{1000} = \\frac{55}{100},\n",
    "$$\n",
    "\n",
    "observamos que la dispersión de la función de verosimilitud al rededor del máximo en el caso de más tiros es menor.\n",
    "\n",
    "¿En cuál de los dos valores estimados $\\hat{\\theta}$ confías más?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Log-verosimilitud\n",
    "\n",
    "Comúnmente hacemos la suposición de que los datos son independientes e idénticamente distribuidos (iid), lo cual trae la implicación que la función de verosimilitud sea un producto de las verosimilitudes individuales de los datos. Ahora, dado que estamos interesados en maximizar la verosimilitud, hay que tener en cuenta que maximizar productos de funciones puede tornarse bastante complejo.\n",
    "\n",
    "Es en este punto donde nos podemos dar cuenta que la función $\\log$ (logaritmo natural o logaritmo en base $e$) puede ser de gran ayuda, dado que convierte productos en sumas. El logaritmo de la función de verosimilitud se conoce como **log-verosimilitud**, y dado que $\\log(x)$ es una función creciente, el máximo de la verosimilitud y la log-verosimilitud se encuentran en el mismo punto.\n",
    "\n",
    "**Ejemplo.** Retomando el caso de la moneda, tenemos que la log-verosimilitud es:\n",
    "\n",
    "$$\n",
    "\\log p(55 | \\theta) = \\log \\left(\\left(\\begin{array}{c}100 \\\\ 55\\end{array}\\right)\\right) + 55 \\log \\theta + 45 \\log (1 - \\theta).\n",
    "$$\n",
    "\n",
    "Ahora, para maximizar la log-verosimilitud:\n",
    "\n",
    "<details>\n",
    "<summary>Descubrir</summary>\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\theta} \\log p(55 | \\theta) = \\frac{55}{\\theta} - \\frac{45}{1 - \\theta}\n",
    "$$\n",
    "\n",
    "Igualando a cero:\n",
    "\n",
    "$$\n",
    "\\begin{align} \\nonumber\n",
    "\\frac{55}{\\theta} - \\frac{45}{1 - \\theta} \\\\ \\nonumber\n",
    "55(1 - \\theta) = 45\\theta \\\\ \\nonumber\n",
    "55 = 100 \\theta\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Por lo que el MLE es $\\hat{\\theta} = \\frac{55}{100}$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como luce la función de log-verosimilitud en este caso y comparémosla con la función de verosimilitud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la función de verosimilitud con los datos del ejemplo\n",
    "# Parámetros - 100 tiros - 55 caras\n",
    "\n",
    "# Función de verosimilitud\n",
    "\n",
    "# Función de log-verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproximamos el máximo de la log-verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujamos las funciones de log-verosimilitud y verosimilitud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Máxima verosimilitud para distirbuciones continuas\n",
    "\n",
    "En el caso que acabamos de analizar teníamos una distribución discreta $\\text{Binomial}$, y obtuvimos la función de verosimilitud usando la pmf. Para distribuciones continuas, todo lo que vimos es completamente aplicable, solo que usaremos la pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.** Suponga que el tiempo de vida de los bombillos es modelado por una distribución exponencial con parámetro desconocido $\\lambda$. Probamos 5 bombillos, y observamos que tienen tiempos de vida de 2, 3, 1, 3, y 4 años, respectivamente. ¿Cuál es el MLE para $\\lambda$?\n",
    "\n",
    "<details>\n",
    "<summary>Descubrir</summary>\n",
    "\n",
    "En este caso, tenemos que la pdf que modela los tiempos de vida es:\n",
    "\n",
    "$$\n",
    "p(x | \\lambda) = \\lambda e^{-\\lambda x}.\n",
    "$$\n",
    "\n",
    "Asumiendo que los tiempos de vida para cada bombillo es independiente e idénticamente distribuido, tenemos que la densidad conjunta es:\n",
    "\n",
    "$$\n",
    "p(x_1, x_2, x_3, x_4, x_5 | \\lambda) = p(x_1 | \\lambda) p(x_2 | \\lambda) p(x_3 | \\lambda) p(x_4 | \\lambda) p(x_5 | \\lambda) = (\\lambda e^{-\\lambda x_1}) (\\lambda e^{-\\lambda x_2}) (\\lambda e^{-\\lambda x_3}) (\\lambda e^{-\\lambda x_4}) (\\lambda e^{-\\lambda x_5}) = \\lambda^5 e^{-\\lambda(x_1 + x_2 + x_3 + x_4 + x_5)}\n",
    "$$\n",
    "\n",
    "Ahora, viendo los datos como fijos, con $x_1=2$, $x_2=3$, $x_3=1$, $x_4=3$, y $x_5=4$, y $\\lambda$ como variable, obtenemos la función de verosimilitud:\n",
    "\n",
    "$$\n",
    "L(\\lambda) = p(2, 3, 1, 3, 4 | \\lambda) = \\lambda^5 e^{-13\\lambda},\n",
    "$$\n",
    "\n",
    "y la log-verosimilitud:\n",
    "\n",
    "$$\n",
    "\\log L(\\lambda) = 5 \\log \\lambda - 13 \\lambda.\n",
    "$$\n",
    "\n",
    "Finalmente, usamos cálculo para encontrar el MLE:\n",
    "\n",
    "$$\n",
    "\\frac{d}{d \\lambda} \\log L(\\lambda) = \\frac{5}{\\lambda} - 13\n",
    "$$\n",
    "\n",
    "Igualando a cero y despejando, obtenemos que el MLE es $\\hat{\\lambda} = \\frac{5}{13}$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parámetros de máxima verosimilitud en una distribución normal (tarea)\n",
    "\n",
    "En este caso tenemos:\n",
    "\n",
    "- Variable aleatoria $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "\n",
    "- $p(x | \\mu,\\sigma^2)=\\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponemos que las observaciones\n",
    "\n",
    "$$\\mathcal{D} = \\{x_1, \\dots, x_N\\}$$\n",
    "\n",
    "son independientes e idénticamente distribuidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar que los estimadores de máxima verosimilitud de $\\mu$ y $\\sigma$ son:\n",
    "\n",
    "$$\\hat{\\mu}_{MLE} = \\frac{1}{N} \\sum_{j=1}^{N}x_j \\qquad \\text{y} \\qquad \\hat{\\sigma}_{MLE} = \\sqrt{\\frac{1}{N}\\sum_{j=1}^{N}(x_j-\\hat{\\mu}_{MLE})^2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numéricamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parámetros de máxima verosimilitud en una distribución de Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este caso tenemos:\n",
    "\n",
    "- Variable aleatoria $X \\sim L(\\mu, b)$.\n",
    "\n",
    "- $p(x | \\mu,b)=\\frac{1}{2 b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponemos que las observaciones\n",
    "\n",
    "$$\\mathcal{D} = \\{x_1, \\dots, x_N\\}$$\n",
    "\n",
    "son independientes e idénticamente distribuidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar que los estimadores de máxima verosimilitud de $\\mu$ y $\\sigma$ son:\n",
    "\n",
    "$$\\hat{\\mu}_{MLE} = \\text{mediana}(\\mathcal{D}) \\qquad \\text{y} \\qquad \\hat{b}_{MLE} = \\frac{1}{N}\\sum_{j=1}^{N}|x_j-\\hat{\\mu}_{MLE}|.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numéricamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comentarios finales\n",
    "\n",
    "El principio de máxima verosimilitud es bastante poderoso, y además una técnica general para estimar los parámetros de un modelo probabilístico. \n",
    "\n",
    "### Overfitting\n",
    "\n",
    "Sin embargo, tiene un problema: **en caso de tener pocos datos de entrenamiento, podemos sobreajustar seriamente el modelo.**\n",
    "\n",
    "### Suposición básica\n",
    "\n",
    "El principio de máxima verosimilitud es bastante intuitivo: estimar los parámetros de manera que se maximice la probabilidad de los datos. Esto trae consigo la suposición subyacente de que los parámetros **son fijos**, de manera que la incertidumbre proviene de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
