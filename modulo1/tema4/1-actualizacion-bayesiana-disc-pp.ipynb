{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actualización Bayesiana Discreta y Predicción Probabilística\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/1/18/Bayes%27_Theorem_MMB_01.jpg\" width=\"500px\" height=\"300px\" />\n",
    "\n",
    "> Como en la vida, que vamos actualizando nuestro conocimiento del mundo con cada nueva experiencia, en inferencia Bayesiana, con cada dato o conjunto de datos que obtenemos, podemos actualizar nuestro conocimiento acerca de la situación que estamos interesados.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Repasar la regla de Bayes para calcular probabilidades.\n",
    "> - Definir e identificar los roles de probabilidad previa, verosimilitud, probabilidad posterior, datos e hipótesis en la aplicación de la regla de Bayes.\n",
    "> - Usar la regla de probabilidad total para calcular probabilidades predictivas previa y posterior.\n",
    "\n",
    "> **Referencias:**\n",
    "> - https://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2022/mit18_05_s22_statistics.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Repaso de la regla de Bayes\n",
    "\n",
    "Recordemos que la regla de Bayes nos permite *invertir* probabilidades condicionales. Dadas V.A. $X$ y $Y$, tenemos que\n",
    "\n",
    "$$\n",
    "p(Y | X) = \\frac{p(X | Y) p(Y)}{p(X)}.\n",
    "$$\n",
    "\n",
    "Esta regla es la base de inferencias estadísticas, no solo en el campo Bayesiano, si no en el frecuentista.\n",
    "\n",
    "Aprovechemos el siguiente ejemplo para introducir algo de terminología acerca de la regla de Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo.** Tenemos tres tipos de monedas con diferentes probabilidades de caer cara:\n",
    "\n",
    "- Tipo A: moneda justa, con probabilidad de cara de $0.5$.\n",
    "- Tipo B: moneda cargada, con probabilidad de cara de $0.6$.\n",
    "- Tipo C: moneda cargada, con probabilidad de cara de $0.9$.\n",
    "\n",
    "Tenemos un recipiente con cinco monedas, dos (2) de tipo A, dos (2) de tipo B y una (1) de tipo C. Seleccionamos una moneda del recipiente de forma aleatoria, y sin mirarla, la tiramos y obtenemos cara. ¿Cuál es la probabilidad de que la moneda sea tipo A?, ¿O tipo B?, ¿O tipo C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución.** Sea $D$ la variable aleatoria que vale 1 si la moneda que sea cae cara, y $T$ la variable aleatoria que representa el tipo de la moneda. $T$ vale:\n",
    "\n",
    "- $T=1$ si la moneda es tipo A,\n",
    "- $T=2$ si la moneda es tipo B,\n",
    "- $T=3$ si la moneda es tipo C.\n",
    "\n",
    "El problema nos pide encontrar\n",
    "\n",
    "$$\n",
    "p(T=1 | D=1), \\qquad p(T=2 | D=1), \\qquad p(T=3 | D=1).\n",
    "$$\n",
    "\n",
    "Veamos algo de terminología:\n",
    "\n",
    "- **Experimento:** se selecciona una moneda aleatoriamnete del recipiente, se tira y se guarda el resultado.\n",
    "\n",
    "- **Datos:** el resultado del experimento. En este caso $D=1$. Pensemos que los datos vienen dados por la variable aleatoria $D$.\n",
    "\n",
    "- **Hipotesis:** estamos probando tres hipótesis. La moneda es tipo A ($T=1$), B ($T=2$), o C ($T=3$).\n",
    "\n",
    "- **Probabilidad previa:** la probabilidad para cada hipótesis antes de tirar la moneda. Dado que el recipiente tiene cinco monedas, dos (2) de tipo A, dos (2) de tipo B y una (1) de tipo C, tenemos que:\n",
    "  \n",
    "  $$\n",
    "  p(T=1) = \\frac{2}{5} = 0.4, \\qquad p(T=2) = \\frac{2}{5} = 0.4, \\qquad p(T=3) = \\frac{1}{5} = 0.2.\n",
    "  $$\n",
    "\n",
    "- **Verosimilitud:** esta es la misma verosimilitud que ya veníamos viendo. La función de verosimilitud $p(D | T)$ es la probabilidad de los datos dada la hipótesis. En el contexto de inferencia Bayseiana, consideramos los datos fijos, y una hipótesis variante. Por ejemplo, en este caso:\n",
    "\n",
    "  $$\n",
    "  p(D=1 | T=1) = 0.5, \\qquad p(D=1 | T=2) = 0.6, \\qquad p(D=1 | T=3) = 0.9.\n",
    "  $$\n",
    "\n",
    "- **Probabilidad posterior:** la probabilidad posterior de cada hipótesis dado el (los) dato(s):\n",
    "\n",
    "  $$\n",
    "  p(T=1 | D=1), \\qquad p(T=2 | D=1), \\qquad p(T=3 | D=1).\n",
    "  $$\n",
    "\n",
    "  Esto es lo que el problema nos pide encontrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos entonces la regla de Bayes para encontrar las probabilidades posteriores:\n",
    "\n",
    "$$\n",
    "p(T|D=1) = \\frac{p(D=1|T) p(T)}{p(D=1)}.\n",
    "$$\n",
    "\n",
    "Los términos del numerador $p(D=1|T)$ y $p(T)$ ya los tenemos. El denominador, lo podemos encontrar con la ley de probabilidad total:\n",
    "\n",
    "$$\n",
    "p(D=1) = p(D=1 | T=1) p(T=1) + p(D=1 | T=2) p(T=2) + p(D=1 | T=3) p(T=3) = 0.5 \\cdot 0.4 + 0.6 \\cdot 0.4 + 0.9 \\cdot 0.2 = 0.62.\n",
    "$$\n",
    "\n",
    "Con esto:\n",
    "\n",
    "$$\n",
    "\\begin{align}\\nonumber\n",
    "p(T=1 | D=1) & = & \\frac{p(D=1|T=1) p(T=1)}{p(D=1)} & = & \\frac{0.5 \\cdot 0.4}{0.62} \\\\ \\nonumber\n",
    "p(T=2 | D=1) & = & \\frac{p(D=1|T=2) p(T=2)}{p(D=1)} & = & \\frac{0.6 \\cdot 0.4}{0.62} \\\\ \\nonumber\n",
    "p(T=3 | D=1) & = & \\frac{p(D=1|T=3) p(T=3)}{p(D=1)} & = & \\frac{0.9 \\cdot 0.2}{0.62}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que la probabilidad total $p(D=1)$ es la misma en todos los denominadores y que es la suma de los tres numeradores. Podemos organizar lo anterior en una tabla de actualización Bayesiana:\n",
    "\n",
    "| Hipótesis | Previa | Verosimilitud | Numerador de Bayes | Posterior    |\n",
    "| --------- | ------ | ------------- | ------------------ | ------------ |\n",
    "| T         | p(T)   | p(D = 1 \\ T)  | p(D = 1 \\ T) p(T)  | p(T \\ D = 1) |\n",
    "|           |        |               |                    |              |\n",
    "| 1         | 0.4    | 0.5           | 0.2                | 0.3226       |\n",
    "| 2         | 0.4    | 0.6           | 0.24               | 0.3871       |\n",
    "| 3         | 0.2    | 0.9           | 0.18               | 0.2903       |\n",
    "|           |        |               |                    |              |\n",
    "| total     | 1      | NO SE SUMA    | p(D = 1) = 0.62    | 1            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar previa y posterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas.** \n",
    "- El numerador de Bayes es el producto de la previa y la verosimilitud.\n",
    "- Vemos en los cálculos que las probabilidades posteriores se obtienen dividiendo el numerador de Bayes entre $p(D=1)=0.62$.\n",
    "- El denominador, que se obtiene por la ley de probabilidad total, es la suma de todos los numeradores de Bayes.\n",
    "\n",
    "\n",
    "El proceso de pasar de la probabilidad previa $p(T)$ a la probabilidad posterior $p(T|D=1)$ se conoce como **actualización Bayesiana**. Este proceso usa los datos, y la regla de Bayes, para actualizar nuestras probabilidades de cada una de las hipótesis.\n",
    "\n",
    "**Más notas.**\n",
    "- La probabilidad posterior para cada hipótesis en la útima columna, nos dice que ahora la moneda tipo B es la más probable, aunque su probabilidad bajó de la previa de 0.4 a la posterior de 0.39. La probabilidad de la moneda tipo C incrementó de 0.2 a 0.29.\n",
    "\n",
    "- El numerador de Bayes determina la probabilidad posterior, la cual se obtiene simplemente reescalando los numeradores para que sumen uno.\n",
    "\n",
    "- Si lo único que nos importara fuera la hipótesis más probable, el numerador de Bayes nos funcionaría igual de bien que la posterior normalizada.\n",
    "\n",
    "- El estimador de máxima verosimilitud en el ejemplo es la hipótesis $T=3$ (moneda tipo C), dado que $p(D=1 | T=3) = 0.9$ es la verosimilitud máxima. La estimación por máxima verosimilitud es útil, pero podemos ver en este ejemplo que no cuenta la historia completa, dado que $T=2$ maximiza la distribución posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos apuntes, podemos expresar la regla de Bayes de una manera más explicativa:\n",
    "\n",
    "$$\n",
    "p(\\text{hipótesis} | \\text{datos}) = \\frac{p(\\text{datos} | \\text{hipótesis}) p(\\text{hpótesis})}{p(\\text{datos})}.\n",
    "$$\n",
    "\n",
    "Con los datos fijos, nos damos cuenta que el denominador $p(\\text{datos})$ es una constante que solo sirve para normalizar la probabilidad posterior para que sume uno. Por tanto:\n",
    "\n",
    "$$\n",
    "p(\\text{hipótesis} | \\text{datos}) \\propto p(\\text{datos} | \\text{hipótesis}) p(\\text{hpótesis})\n",
    "$$\n",
    "\n",
    "o equivalentemente:\n",
    "\n",
    "$$\n",
    "\\text{posterior} \\propto \\text{verosimilitud} \\cdot \\text{previa}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.** Rehacer el ejemplo, pero ahora suponiendo que después de tirar la moneda, se obtiene sello, es decir $D=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Actualizamos una y otra vez...\n",
    "\n",
    "Como en la vida, que vamos actualizando nuestro conocimiento del mundo con cada nueva experiencia, en inferencia Bayesiana, después de actualizar la previa a la posterior, podemos obtener más datos y actualizar de nuevo. En esta segunda actualización, la posterior del primer paso, se convierte en la previa para el segundo paso.\n",
    "\n",
    "**Ejemplo** Supongamos que elegimos una moneda como en el ejemplo anterior. La tiramos y obtenemos cara. Tomamos la misma moned y la tiramos, y volvemos a obtener cara. ¿Cuál es la probabilidad de que la moneda sea tipo A?, ¿O tipo B?, ¿O tipo C?\n",
    "\n",
    "**Solución.** Retomamos la tabla del ejemplo anterior, ahora llamando $D_1$ a la variable que representa el primer tiro de la moneda y $D_2$ a la variable que representa el segundo tiro:\n",
    "\n",
    "| Hipótesis | Previa | Verosimilitud     | Numerador de Bayes 1   | Posterior        |\n",
    "| --------- | ------ | ----------------- | ---------------------- | ---------------- |\n",
    "| T         | p(T)   | p($D_1$ = 1 \\ T)  | p($D_1$ = 1 \\ T) p(T)  | p(T \\ $D_1$ = 1) |\n",
    "|           |        |                   |                        |                  |\n",
    "| 1         | 0.4    | 0.5               | 0.2                    | 0.3226           |\n",
    "| 2         | 0.4    | 0.6               | 0.24                   | 0.3871           |\n",
    "| 3         | 0.2    | 0.9               | 0.18                   | 0.2903           |\n",
    "|           |        |                   |                        |                  |\n",
    "| total     | 1      | NO SE SUMA        | p($D_1$ = 1) = 0.62    | 1                |\n",
    "\n",
    "Ahora, construimos la tabla para el segundo paso. Podemos usar el numerador 1 para construir el numerador 2. Como solo estamos interesados en la posterior final, no es necesario normalizar el primer paso:\n",
    "\n",
    "| Hipótesis | Numerador de Bayes 1    | Verosimilitud     | Numerador de Bayes 2                    | Posterior                   |\n",
    "| --------- | ----------------------- | ----------------- | --------------------------------------- | --------------------------- |\n",
    "| T         | p($D_1$ = 1 \\ T) p(T)   | p($D_2$ = 1 \\ T)  | p($D_2$ = 1 \\ T) p($D_1$ = 1 \\ T) p(T)  | p(T \\ $D_1$ = 1, $D_2$ = 1) |\n",
    "|           |                         |                   |                                         |                             |\n",
    "| 1         | 0.2                     | 0.5               | 0.1                                     | 0.2463                      |\n",
    "| 2         | 0.24                    | 0.6               | 0.144                                   | 0.3547                      |\n",
    "| 3         | 0.18                    | 0.9               | 0.162                                   | 0.3990                      |\n",
    "|           |                         |                   |                                         |                             |\n",
    "| total     | 0.62                    | NO SE SUMA        | 0.406                                   | 1                           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar previa y posteriorres en cada caso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, la hipótesis $T=3$ es ahora lo más probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicción probabilística\n",
    "\n",
    "En las secciones anteriores, vimos como actualizar la probabilidad de las hipótesis basados en datos. También podemos usar los datos para actualizar las probabilidades de cada posible resultado de un experimento futuro.\n",
    "\n",
    "Lectura recomendada: https://en.wikipedia.org/wiki/Words_of_estimative_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad predictiva previa\n",
    "\n",
    "De esto es todo lo que se trata la predicción probabilística: *asignar una probabilidad a cada posible resultado de un experimento*.\n",
    "\n",
    "Retomamos el ejemplo que hemos venido trabajando, donde tenemos tres tipos monedas que son indistinguibles, solo tienen diferente probabilidad de caer en cara:\n",
    "\n",
    "- Tipo A: moneda justa, con probabilidad de cara de $0.5$.\n",
    "- Tipo B: moneda cargada, con probabilidad de cara de $0.6$.\n",
    "- Tipo C: moneda cargada, con probabilidad de cara de $0.9$.\n",
    "\n",
    "Tenemos un recipiente con CUATRO monedas, dos (2) de tipo A, una (1) de tipo B y una (1) de tipo C. En este sentido, tenemos que nuestra nueva previa es\n",
    "\n",
    "$$\n",
    "p(T=1) = \\frac{2}{4} = 0.5, \\qquad p(T=2) = \\frac{1}{4} = 0.25, \\qquad p(T=3) = \\frac{1}{4} = 0.25.\n",
    "$$\n",
    "\n",
    "Antes de generar datos, podemos calcular la probabilidad de que al hacer el experimento de tomar una moneda de forma aleatoria, y lanzar la moneda al aire, caiga cara. Para esto, podemos usar la regla de probabilidad total (ver diagrama de arbol en el pizarrón):\n",
    "\n",
    "> Recordamos que D es la V.A. que vale 1 si la moneda cae cara y 0 si cae sello.\n",
    "\n",
    "$$\n",
    "\\begin{align} \\nonumber\n",
    "p(D=1) & = & p(D=1|T=1) p(T=1) + p(D=1|T=2) p(T=2) + p(D=1|T=3) p(T=3) \\\\ \\nonumber\n",
    "       & = & 0.5 \\cdot 0.5 + 0.6 \\cdot 0.25 + 0.9 \\cdot 0.25 \\\\ \\nonumber\n",
    "       & = & 0.625\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Pregunta.** ¿Cuánto es $p(D=0)$\n",
    "\n",
    "<details>\n",
    "  <summary>Descubrir</summary>\n",
    "  \n",
    "Se puede usar la regla de la probabilidad de nuevo, o simplemente:\n",
    "\n",
    "$$\n",
    "p(D=0) = 1 - p(D=1) = 0.375\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas probabilidades dan una predicción (probabilística) de lo que sucederá si la moneda se tira. Dado que se calculan antes de obtener datos, con las probabilidades previas se conocen como **probabilidades predictivas previas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad predictiva posterior\n",
    "\n",
    "Ahora supongamos que la moneda se tira una vez y cae cara. En este caso, conocemos el dato $D_1 = 1$ que podemos usar para actualizar las probabilidades previas de nuestras hipótesis, a probabilidades posteriores.\n",
    "\n",
    "Usando una tabla de actualización Bayesiana:\n",
    "\n",
    "| Hipótesis | Previa | Verosimilitud     | Numerador de Bayes 1   | Posterior        |\n",
    "| --------- | ------ | ----------------- | ---------------------- | ---------------- |\n",
    "| T         | p(T)   | p($D_1$ = 1 \\ T)  | p($D_1$ = 1 \\ T) p(T)  | p(T \\ $D_1$ = 1) |\n",
    "|           |        |                   |                        |                  |\n",
    "| 1         | 0.5    | 0.5               | 0.25                   | 0.4              |\n",
    "| 2         | 0.25   | 0.6               | 0.15                   | 0.24             |\n",
    "| 3         | 0.25   | 0.9               | 0.225                  | 0.36             |\n",
    "|           |        |                   |                        |                  |\n",
    "| total     | 1      | NO SE SUMA        | p($D_1$ = 1) = 0.625   | 1                |\n",
    "\n",
    "Con la distribución posterior actualizada, podemos calcular la probabilidad de que la moneda caiga cara (o sello) si tiramos la moneda una segunda vez. El procedimiento es el mismo que el anterior, solo que usamos la posterior en lugar de la previa:\n",
    "\n",
    "$$\n",
    "\\begin{align} \\nonumber\n",
    "p(D_2=1|D_1=1) & = & p(D_2=1|T=1) p(T=1|D_1=1) + p(D_2=1|T=2) p(T=2|D_1=1) + p(D_2=1|T=3) p(T=3|D_1=1) \\\\ \\nonumber\n",
    "               & = & 0.5 \\cdot 0.4 + 0.6 \\cdot 0.24 + 0.9 \\cdot 0.36 \\\\ \\nonumber\n",
    "               & = & 0.668,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "y\n",
    "\n",
    "$$\n",
    "p(D_2=0|D_1=1) = 1 - p(D_2=1|D_1=1) = 0.332.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas nuevas probabilidades dan una predicción (probabilística) de lo que sucederá si la moneda se tira nuevamente. Dado que se calculan después de obtener datos y actualizar las previas a las posteriores, se conocen como **probabilidades predictivas posteriores**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mebo2024_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
