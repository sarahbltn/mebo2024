{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestreo de distribuciones generales\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/bf/Simple_random_sampling.PNG\" width=\"400px\" height=\"400px\" />\n",
    "\n",
    "> Ya nos hicimos una idea básica de lo que es la estimación Montecarlo. Vimos que es fundamental poder muestrear las distribuciones, y por ello vimos métodos para muestrear distribuciones en una dimensión, tanto discretas como continuas.\n",
    "\n",
    "> Ahora, ¿Qué pasa si nuestra distribución es multivariable? Bien, en este notebook estaremos viendo métodos generales para muestrear cualquier distribución através de cadenas de Markov.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Estudiar las cadenas de Markov, sus componentes y propiedades básicas.\n",
    "> - Entender las cadenas de Markov como artefactos para muestrar distribuciones.\n",
    "> - Comprender la técnica de muestreo de Gibbs.\n",
    "> - Comprender la técnica de muestreo de Metropolis-Hastings.\n",
    "> - Comprender la técnica de muestreo de Montecarlo Hamiltoniano.\n",
    "\n",
    "> **Referencias:**\n",
    "> - Bayesian Methods for Machine Learning course, HSE University, Coursera.\n",
    "> - Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Ch. 12.\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://upload.wikimedia.org/wikipedia/commons/b/bf/Simple_random_sampling.PNG.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cadenas de Markov\n",
    "\n",
    "Una cadena de Markov es un **modelo de transiciones probabilístico** sobre ciertos estados $x$. Para ello definimos la probabilidad de transicionar de un estado $x$ a otro estado $x'$ como $T(x \\to x')$, y al ser una probabilidad debe cumplir que:\n",
    "\n",
    "$$\n",
    "\\forall x: \\sum_{x'}T(x \\to x') = 1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo.\n",
    "\n",
    "Consideramos la trayectoria de un borracho modelada por la siguiente cadena de Markov:\n",
    "\n",
    "![](figures/drunkMC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada arco representa la probabilidad de transicionar de un estado a otro (incluyendo al mismo estado de partida). Por ejemplo, en la cadena de Markov de arriba:\n",
    "\n",
    "$$\n",
    "T(0 \\to 0) = 0.5, \\quad T(0 \\to 1) = 0.25, \\quad T(0 \\to -1) = 0.25, \\quad T(0 \\to -2) = T(0 \\to 2) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, si el borracho está en la posición $0$, tiene un 50% de probabilidad de permanecer allí, y un 25% de moverse a las posiciones $1$ y $-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una pregunta natural es:\n",
    "\n",
    "- En determinado instante $t$, ¿Cuál es la probabilidad $p^{(t)}(x^{(t)})$ de que el borracho esté en determinada posición?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta es:\n",
    "\n",
    "- Dada una distribución inicial de probabilidad $p^{(0)}(x^{(0)})$, podemos encontrar $p^{(t)}(x^{(t)})$ como:\n",
    "\n",
    "  $$\n",
    "  p^{(t+1)}(x^{(t+1)} = x') = \\sum_{x} p^{(t)}(x^{(t)}) T(x \\to x').\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si sabemos que el borracho comenzó en la posición $0$, tenemos que:\n",
    "\n",
    "| $p^{(t)}(x^{(t)})$ | $x^{(t)}=-2$ | $x^{(t)}=-1$ | $x^{(t)}=0$ | $x^{(t)}=1$ | $x^{(t)}=2$ |\n",
    "| ------------------ | ------------ | ------------ | ----------- | ----------- | ----------- |\n",
    "| $p^{(0)}(x^{(0)})$ | $0$          | $0$          | $1$         | $0$         | $0$         |\n",
    "| $p^{(1)}(x^{(1)})$ | $0$          | $0.25$       | $0.5$       | $0.25$      | $0$         |\n",
    "| $p^{(2)}(x^{(2)})$ | $0.0625$     | $0.25$       | $0.375$     | $0.25$      | $0.0625$    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicar estos valores en el pizarrón.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tabla la podemos continuar todo lo que queramos, y veremos que después de algunas iteraciones **todos los valores convergerán a $0.2$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de transición\n",
    "\n",
    "\n",
    "# Distribución inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalentemente (productos sucesivos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalentemente (potenciación de la matriz de transición)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo podemos interpretar esto?**\n",
    "\n",
    "Supongamos que dejamos caminar al borracho durante varios pasos (digamos 1000) y obtenemos la siguiente secuencia:\n",
    "\n",
    "$$\n",
    "0, 0, 1, 2, 1, \\dots, -1\n",
    "$$\n",
    "\n",
    "Podemos hacer lo mismo repetidas veces:\n",
    "\n",
    "$$\n",
    "0, 1, 1, 0, 1, \\dots, 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "0, 1, 0, -1, 0, \\dots, 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "0, 1, 0, -1, -2, \\dots, 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "0, -1, -2, -2, -1, \\dots, -2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, podemos tomar las últimas observaciones en cada caso ($-1$, $2$, $0$, $1$, y $-2$) que corresponden a muestras de la distribución del paso número 1000 dado que el borracho comenzó en la posición 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos anteriormente, estas muestras corresponderán a la distribución discreta uniforme:\n",
    "\n",
    "$$\n",
    "p(x = i) = 0.2, \\quad \\forall i \\in \\{-2, -1, 0, 1, 2\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una manera muy extravagante de generar muestras de esta distribución, pues ya vimos en el notebook pasado que hay maneras mucho más sencillas de hacerlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, esto nos da una idea de qué hacer en casos más complejos: **podemos construir una cadena de markov que converja a una distribución deseada y después tomar las muestras de allí**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, queremos muestrear de una distribución $p(x)$:\n",
    "\n",
    "1. Construimos una cadena de Markov que converge a $p(x)$.\n",
    "\n",
    "2. Comenzamos desde algún punto inicial $x_0$.\n",
    "\n",
    "3. Simulamos la cadena de Markov por muchas muestras:\n",
    "   \n",
    "   $$\n",
    "   x_k \\sim T(x_{k-1} \\to x_k)\n",
    "   $$\n",
    "   \n",
    "4. Si dejamos pasar suficientes muestras, las siguientes $x_k$ corresponderán a muestras de la distribución deseada $p(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una pregunta natural es:\n",
    "\n",
    "**¿Siempre converge una cadena de Markov?**\n",
    "\n",
    "La respuesta es no siempre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar a hablar de convergencia, primero definimos:\n",
    "\n",
    "> *Definición.* Una distribución $\\pi$ es estacionaria en la cadena de Markov con transición $T$ si:\n",
    ">\n",
    "> $$\\pi(x') = \\sum_{x} \\pi(x) T(x \\to x').$$\n",
    "\n",
    "Básicamente si de un instante de tiempo al siguiente la distribución no cambia, entocnes es estacionaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Definition (Regular Markov chain).* Una cadena de Markov se llama **regular** si existe $k\\in\\mathbb{N}$ tal que, para cada par $x, x'$, la probabilidad de llegar de $x$ a $x'$ en $k$ pasos es positiva ($>0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Teorema.* Una cadena de Markov regular converge siempre a una única distribución $\\pi(x)$ sin importar la distribución inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, la cadena de Markov del borracho es regular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución inicial diferente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces ya sabemos definir cadenas de Markov convergentes. Ahora, **¿Cómo hacer para que converjan a una distribución deseada?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Muestreo de Gibbs\n",
    "\n",
    "Para responder a la anterior pregunta, surge la metodología del muestreo de Gibbs.\n",
    "\n",
    "Supongamos que tenemos una distribución (no normalizada) de tres dimensiones (puede tener dimensiones arbitrarias):\n",
    "\n",
    "$$\n",
    "p(x_1, x_2, x_3) = \\frac{\\tilde{p}(x_1, x_2, x_3)}{Z}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:**\n",
    "\n",
    "1. Comenzamos con un punto inicial $(x_1^0, x_2^0, x_3^0)$.\n",
    "\n",
    "2. Muestreamos de la siguiente manera:\n",
    "\n",
    "   $$\n",
    "   x_1^1 \\sim p(x_1 | x_2^0, x_3^0)\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   x_2^1 \\sim p(x_2 | x_1^1, x_3^0)\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   x_3^1 \\sim p(x_3 | x_1^1, x_2^1)\n",
    "   $$\n",
    "   \n",
    "   - Notemos que vamos reemplazando las muestras que vamos generando inmediatamente. No se puede paralelizar.\n",
    "   - Muestreo de distribuciones unidimensionales.\n",
    "   - Si conocemos solo la distribución no normalizada, no hay problema: $p(x_1 | x_2^0, x_3^0) = \\frac{\\tilde{p}(x_1, x_2^0, x_3^0)}{Z_1}$\n",
    "\n",
    "3. Y así sucesivamente:\n",
    "\n",
    "   $$\n",
    "   x_1^{k} \\sim p(x_1 | x_2^{k-1}, x_3^{k-1})\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   x_2^{k} \\sim p(x_2 | x_1^{k}, x_3^{k-1})\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   x_3^{k} \\sim p(x_3 | x_1^{k}, x_2^{k})\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué funciona?\n",
    "\n",
    "Veámoslo desde el punto de vista de redes de Markov. Queremos probar que $p$ es una distribución estacionaria:\n",
    "\n",
    "$$\n",
    "p(x', y', z') = \\sum_{x, y, z} T(x, y, z \\to x', y', z') p(x, y, z).\n",
    "$$\n",
    "\n",
    "Para el muestreo de Gibbs, tenemos que la transición es:\n",
    "\n",
    "$$\n",
    "T(x, y, z \\to x', y', z') = p(x' | y, z) p(y' | x', z) p(z' | x', y').\n",
    "$$\n",
    "\n",
    "Concentrémonos en el lado derecho de la igualdad:\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_{x, y, z} p(x' | y, z) p(y' | x', z) p(x, y, z) & =  p(z' | x', y')\\sum_{y, z} p(x' | y, z) p(y' | x', z) \\underbrace{\\sum_{x} p(x, y, z)}_{p(y, z)} \\\\\n",
    "& = p(z' | x', y')\\sum_{z} p(y' | x', z) \\underbrace{\\sum_{y} \\underbrace{p(x' | y, z) p(y, z)}_{p(x', y, z)}}_{p(x', z)} \\\\\n",
    "& = p(z' | x', y')\\underbrace{\\sum_{z} \\underbrace{p(y' | x', z) p(x', z)}_{p(x', y', z)}}_{p(x', y')} \\\\\n",
    "& = p(z' | x', y')p(x', y') \\\\\n",
    "& = p(x', y', z').\n",
    "\\end{align}\n",
    "\n",
    "Tal y como queríamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "- Esta misma idea se puede replicar para un número arbitrario de dimensiones.\n",
    "\n",
    "- También funciona en el caso continuo, reemplazando sumas por integrales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "Tomado del [siguiente enlace](https://towardsdatascience.com/gibbs-sampling-8e4844560ae5)\n",
    "\n",
    "Supongamos que queremos muestrear la siguiente distribución:\n",
    "\n",
    "$$\n",
    "p(x, y) = \\frac{1}{Z} \\exp \\left\\{- \\frac{x^2 y^2 + x^2 + y^2 - 8x - 8y}{2} \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "# Importamos numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rare_pdf(x, y):\n",
    "    return np.exp(-(x**2 * y**2 + x**2 +y**2 - 8 * x - 8 * y) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "x = np.linspace(-1, 6, 100)\n",
    "y = np.linspace(-1, 6, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = rare_pdf(x, y)\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot_surface(x, y, z)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.contour(x, y, z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que necesitamos las distribuciones condicionales:\n",
    "\n",
    "$$\n",
    "p(x | y) = \\frac{p(x, y)}{p(y)} = \\frac{1}{Z(y)} \\exp\\left\\{-\\left(x - \\frac{4}{1 + y^2}\\right)^2 \\frac{1}{2\\frac{1}{1+y^2}}\\right\\} \\propto \\mathcal{N}\\left(x\\left\\lvert \\frac{4}{1 + y^2}, \\frac{1}{1 + y^2}\\right.\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(y | x) = \\frac{p(x, y)}{p(x)} = \\frac{1}{Z(x)} \\exp\\left\\{-\\left(y - \\frac{4}{1 + x^2}\\right)^2 \\frac{1}{2\\frac{1}{1+x^2}}\\right\\} \\propto \\mathcal{N}\\left(y\\left\\lvert \\frac{4}{1 + x^2}, \\frac{1}{1 + x^2}\\right.\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punto inicial\n",
    "x0 = np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling(x0, M):\n",
    "    \n",
    "    # Prealloc de variables\n",
    "    xs = np.zeros((M + 1, len(x0)))\n",
    "    xs[0, :] = x0\n",
    "    \n",
    "    for k in range(M):\n",
    "        xk, yk = xs[k, :]\n",
    "        \n",
    "        # Muestreamos x^{k+1} de la condicional p(x | y^{k})\n",
    "        \n",
    "        \n",
    "        # Muestreamos y^{k+1} de la condicional p(y | x^{k+1})\n",
    "        \n",
    "        \n",
    "        # Guardamos siguiente muestra\n",
    "        xs[k + 1, 0] = xk1\n",
    "        xs[k + 1, 1] = yk1\n",
    "        \n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = gibbs_sampling(x0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "plt.figure(figsize=(5, 5))\n",
    "x = np.linspace(-1, 6, 100)\n",
    "y = np.linspace(-1, 6, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = rare_pdf(x, y)\n",
    "plt.contour(x, y, z)\n",
    "plt.scatter(xs[:, 0], xs[:, 1], alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como idea importante, podemos observar que nunca conocimos la distribución $p(x,y)$ normalizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metropolis-Hastings\n",
    "\n",
    "El muestreo de Gibbs parece hacer un buen trabajo. Sin embargo, por la manera en que se obtienen las muestras, éstas están muy correlacionadas, y recordemos que muchos análisis los basamos en el supuesto de iid.\n",
    "\n",
    "Así que en esta sección estudiaremos un método para producir muestras no correlacionadas. La idea básica de este método es generalizar la técnica de muestreo y rechazo para distribuciones en general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**\n",
    "\n",
    "1. Comenzamos con un punto inicial $(x_1^0, x_2^0, x_3^0)$.\n",
    "\n",
    "2. Muestreamos $x^{k+1}$ de una distribución $Q(x^{k} \\to x')$, que en principio no tiene nada que ver con la distribución deseada $p(x)$, sino que está diseñada para explorar el espacio (evitar correlación).\n",
    "\n",
    "3. Aceptamos la muestra $x'$ con probabilidad $A(x^{k} \\to x')$.\n",
    "   - Dado que $Q(x^{k} \\to x')$ quiere explorar tooodo el espacio, debemos evitar que muchas muestras caigan en una región de baja probabilidad de la distribución deseada $p(x)$.\n",
    "   \n",
    "   De manera que la transición es:\n",
    "   $$\n",
    "   T(x \\to x') = Q(x \\to x') A(x \\to x').\n",
    "   $$\n",
    "   \n",
    "   - Si no se acepta la muestra, hacemos $x^{k+1}=x^k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo elegimos la probabilidad de aceptación $A(x \\to x')$?**\n",
    "\n",
    "Bueno, pues debemos de asegurarnos que la distribución deseada $p(x)$ sea estacionaria:\n",
    "\n",
    "$$\n",
    "p(x') = \\sum_{x} p(x) T(x \\to x').\n",
    "$$\n",
    "\n",
    "Sin embargo esta condición es compleja de satisfacer directamente, e involucraría restricciones sobre $A$ y $Q$.\n",
    "\n",
    "La idea es que se elija $Q$ independientemente, y después de eso, diseñar $A$ para que todo funcione correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una condición que implica estacionariedad, y es la siguiente:\n",
    "\n",
    "> *Teorema*. Si $p(x) T(x \\to x') = p(x') T(x' \\to x)$, entonces\n",
    "  $$\n",
    "p(x') = \\sum_{x} p(x) T(x \\to x').\n",
    "$$\n",
    "\n",
    "> *Prueba.*\n",
    "> Observamos que\n",
    "  $$\n",
    "  \\sum_{x} p(x) T(x \\to x') = \\sum_{x} p(x') T(x' \\to x) = p(x') \\underbrace{\\sum_x T(x' \\to x)}_{1}.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, si elegimos $A$ de manera que se satisfaga $p(x) T(x \\to x') = p(x') T(x' \\to x)$, aseguraremos que $p(x)$ sea la distribución estacionaria deseada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos:\n",
    "\n",
    "\\begin{align}\n",
    "            & p(x) T(x \\to x') = p(x') T(x' \\to x) \\\\\n",
    "\\Rightarrow & p(x) Q(x \\to x') A(x \\to x') = p(x') Q(x' \\to x) A(x' \\to x) \\\\\n",
    "\\Rightarrow & \\frac{A(x \\to x')}{A(x' \\to x)} = \\frac{p(x') Q(x' \\to x)}{p(x) Q(x \\to x')} = \\rho\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta razón la podemos calcular dado que $p(x)$ es la distribución deseada, y $Q$ la proponemos nosotros.\n",
    "\n",
    "Ahora, tenemos dos posibildades:\n",
    "\n",
    "1. $\\rho \\leq 1$ \n",
    "\n",
    "   En este caso, podemos asignar:\n",
    "   \n",
    "   $$\n",
    "   A(x \\to x') = \\rho, \\quad A(x' \\to x)=1,\n",
    "   $$\n",
    "   \n",
    "   de modo que $\\frac{A(x \\to x')}{A(x' \\to x)} = \\rho$.\n",
    "   \n",
    "2. $\\rho > 1$ \n",
    "\n",
    "   En este caso, podemos asignar:\n",
    "   \n",
    "   $$\n",
    "   A(x \\to x') = 1, \\quad A(x' \\to x)=\\frac{1}{\\rho},\n",
    "   $$\n",
    "   \n",
    "   de modo que $\\frac{A(x \\to x')}{A(x' \\to x)} = \\rho$.\n",
    "   \n",
    "   \n",
    "De esta manera, la selección de $A$ será en general:\n",
    "\n",
    "$$\n",
    "A(x \\to x') = \\min \\left\\{1, \\frac{p(x') Q(x' \\to x)}{p(x) Q(x \\to x')}\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, observamos que con esta selección, no necesitamos conocer $p(x)$ normalizada, dado en la razón se cancela la constante de normalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante**\n",
    "\n",
    "1. $Q$ debe ser una distribución **positiva**.\n",
    "\n",
    "2. Debemos elegir $Q$ para explorar el espacio de estados exhaustivamente, para generar muestras independientes. Sin embargo, si $Q$ explora mucho las regiones de baja densidad de $p$ entonces tendremos poca probabilidad de aceptación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "De nuevo, queremos muestrear la distribución:\n",
    "\n",
    "$$\n",
    "p(x_1, x_2) = \\frac{1}{Z} \\exp \\left\\{- \\frac{x_1^2 x_2^2 + x_1^2 + x_2^2 - 8x_1 - 8x_2}{2} \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proponemos la siguiente distribución $Q(x \\to x')$:\n",
    "\n",
    "$$\n",
    "Q(x \\to x') = \\mathcal{N}\\left(x'\\left\\lvert x, I\\right.\\right) = \\mathcal{N}\\left(x\\left\\lvert x', I\\right.\\right) = Q(x' \\to x),\n",
    "$$\n",
    "\n",
    "la cual es simétrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera tenemos que:\n",
    "\n",
    "$$\n",
    "A(x \\to x') = \\min \\left\\{1, \\frac{p(x') Q(x' \\to x)}{p(x) Q(x \\to x')}\\right\\} = \\min \\left\\{1, \\frac{p(x')}{p(x)}\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punto inicial\n",
    "x0 = np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(x0, M):\n",
    "    \n",
    "    # Prealloc de variables\n",
    "    xs = np.zeros((M + 1, len(x0)))\n",
    "    xs[0, :] = x0\n",
    "    \n",
    "    for k in range(M):\n",
    "        xk = xs[k, :]\n",
    "        \n",
    "        # Muestreamos x' de Q(x -> x')\n",
    "        \n",
    "        \n",
    "        # Evaluamos A\n",
    "        \n",
    "        \n",
    "        # Guardamos siguiente muestra\n",
    "        if np.random.uniform() < A:\n",
    "            xs[k + 1, :] = xk1\n",
    "        else:\n",
    "            xs[k + 1, :] = xk\n",
    "        \n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = metropolis_hastings(x0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántos no repetidos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsu = np.unique(xs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "plt.figure(figsize=(5, 5))\n",
    "x = np.linspace(-1, 6, 100)\n",
    "y = np.linspace(-1, 6, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = rare_pdf(x, y)\n",
    "plt.contour(x, y, z)\n",
    "plt.scatter(xsu[:, 0], xsu[:, 1], alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo cambian los $x_s$ con la variabilidad de $Q$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios**\n",
    "\n",
    "1. Similarmente, no necesitamos conocer la distribución normalizada.\n",
    "\n",
    "2. Es una generalización del algoritmo de muestreo y rechazo para distribuciones en general.\n",
    "\n",
    "3. Mucho más fácil de implementar que el muestreo de Gibbs, dado que no tenemos que calcular las distribuciones condicionales.\n",
    "\n",
    "4. Pero debemos elegir una distribución $Q$ apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCMC Hamiltoniano\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Parece ser un principio general que, siempre que hay una forma aleatoria de hacer algo, existe una forma no aleatoria que da mejores resultados, pero requiere más pensamiento. - [E. T. Jaynes](https://es.wikipedia.org/wiki/Edwin_Thompson_Jaynes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de Metropolis-Hastings parece bastante bueno. Es fácil de implementar, una vez se diseña una distribución de exploración $Q$. Acá el [artículo original](https://bayes.wustl.edu/Manual/EquationOfState.pdf)\n",
    "\n",
    "Sin embargo, al ser un algoritmo de muestreo y rechazo, muchas veces se descartan demasiadas muestras, lo que lo lleva a ser ineficiente. En el ejemplo de arriba, nos quedamos con solamente ~350 muestras únicas de las 1000 generadas.\n",
    "\n",
    "Haciendo referencia a la acotación de Jaynes, parece que el algoritmo de Gibbs es menos aleatorio, dado que se explota el conocimiento de la distribución al costo de tener que calcular las distribuciones condicionales. Sin embargo, el algoritmo de Gibbs tiene el problema que las muestras consecutivas poseen una correlación alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado lo anterior, han habido varias contribuciones e innovaciones en la última década. Un camino de innovación ha sido la interpretación física de las distribuciones de probabilidad, incluyendo el uso de gradientes. Esto se conoce como **Montecarlo Hamiltoniano** (HMC). \n",
    "\n",
    "Este método, lleva la acotación de Jaynes más allá. Su costo computacional es mucho más alto comparado con los algoritmos de Gibbs o Metrópolis, pero las muestras que se obtienen son mucho más eficientes en el sentido de que no están tan correlacionadas, y que no se rechaza ninguna de ellas. A final de cuentas el tiempo de cómputo necesario comúnmente resulta ser menor con HMC, porque aunque cada muestra de HMC sea más costosa, no se descarta niguna. Esto es especialmente relevante cuando tenemos modelos complejos con muchos parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo funciona HMC?\n",
    "\n",
    "El HMC hace un simil de la distribución de probabilidad como si fuera un fenómeno físico. Tenemos \"una partícula que se va a mover sobre la distribución de probabilidad\", y a intervalos fijos \"de tiempo\" se toman las muestras.\n",
    "\n",
    "En cada punto de muestra, se asigna un momentum o velocidad inicial, y se \"deja\" que la partícula se mueva sobre la distribución hasta que llegue el momento de tomar otra muestra.\n",
    "\n",
    "Para generar esta \"simulación\" necesitamos:\n",
    "\n",
    "1. La distribución de probabilidad negativa logarítmica $U$.\n",
    "2. El gradiente de la distribución de probabilidad negativa logarítmica $\\nabla U$. Este se utilizará para determinar el movimiento de la partícula.\n",
    "3. El tamaño de paso $\\epsilon$. La simulación no se hace de forma continua, sino discreta.\n",
    "4. El número fijo de pasos $L$ al que se toman las muestras.\n",
    "5. La muestra inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo con el ejemplo anterior:\n",
    "\n",
    "$$\n",
    "p(x, y) = \\frac{1}{Z} \\exp \\left\\{- \\frac{x^2 y^2 + x^2 + y^2 - 8x - 8y}{2} \\right\\},\n",
    "$$\n",
    "\n",
    "tenemos que $U(x, y) = - \\log p(x, y)$:\n",
    "\n",
    "$$\n",
    "U(x, y) = \\log(Z) + \\frac{x^2 y^2 + x^2 + y^2 - 8x - 8y}{2}.\n",
    "$$\n",
    "\n",
    "con esto:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial U}{\\partial x} = x (y^2 + 1)  - 4 \\qquad \\frac{\\partial U}{\\partial y} = y (x^2 + 1) - 4\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U(x):\n",
    "    x, y = x[0], x[1]\n",
    "    return (x**2 * y**2 + x**2 + y**2 - 8 * x - 8 * y) / 2\n",
    "\n",
    "def grad_U(x):\n",
    "    x, y = x[0], x[1]\n",
    "    return np.array([\n",
    "        x * (y**2 + 1) - 4,  # dU / dx\n",
    "        y * (x**2 + 1) - 4   # dU / dy\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmc(U, grad_U, epsilon, L, current_q):\n",
    "    q = current_q\n",
    "    \n",
    "    # Momentum\n",
    "    p = np.random.normal(size=len(q))\n",
    "    current_p = p\n",
    "    \n",
    "    # Alinear el momentum con el modelo\n",
    "    p = p - epsilon * grad_U(q) / 2\n",
    "    \n",
    "    # Inicialización de la trayectoria\n",
    "    qtraj = np.zeros((L + 1, len(q)))\n",
    "    ptraj = np.zeros((L + 1, len(q)))\n",
    "    qtraj[0, :] = current_q\n",
    "    ptraj[0, :] = p\n",
    "    \n",
    "    # Actualizar posición y velocidad\n",
    "    for i in range(1, L + 1):\n",
    "        q = q + epsilon * p  #  Cambio en la posición\n",
    "        # Make a full step for the momentum, except at end of trajectory\n",
    "        if i < L:\n",
    "            p = p - epsilon * grad_U(q)\n",
    "            ptraj[i] = p\n",
    "        qtraj[i] = q\n",
    "\n",
    "    # Alinear velocidad final con el modelo\n",
    "    p = p - epsilon * grad_U(q) / 2\n",
    "    ptraj[L, :] = p\n",
    "\n",
    "    # Evaluar energías cinética y potencial al inicio y final de la trauectoria\n",
    "    current_U = U(current_q)\n",
    "    current_K = (current_p**2).sum() / 2\n",
    "    proposed_U = U(q)\n",
    "    proposed_K = (p**2).sum() / 2\n",
    "    # Acepta o rechaza el estado al final de la trayectoria:\n",
    "    # Excepcionalmente se admite un aumento pequeño de energía\n",
    "    accept = 0\n",
    "    new_q = current_q\n",
    "    if np.random.uniform() < np.exp(current_U - proposed_U + current_K - proposed_K):\n",
    "        new_q = q  # Accept\n",
    "        accept = 1\n",
    "    return new_q, qtraj, ptraj, accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores\n",
    "q = np.ones(2)\n",
    "L = 23\n",
    "n_samples = 1000\n",
    "Q = np.zeros((n_samples + 1, len(q)))\n",
    "Q[0, :] = q\n",
    "epsilon = 0.05\n",
    "# Simulación\n",
    "for i in range(1, n_samples + 1):\n",
    "    Q[i, :], _, _, _ = hmc(U, grad_U, epsilon, L, Q[i - 1, :])\n",
    "\n",
    "Qu = np.unique(Q, axis=0)\n",
    "Qu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "plt.figure(figsize=(5, 5))\n",
    "x = np.linspace(-1, 6, 100)\n",
    "y = np.linspace(-1, 6, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = rare_pdf(x, y)\n",
    "plt.contour(x, y, z)\n",
    "plt.scatter(Qu[:, 0], Qu[:, 1], alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior, podemos ver que el HMC es por mucho el más complejo de programar, pero trae como ventaja que es muy eficiente en cuanto al número de muestras; además estas muestras son poco correlacionadas.\n",
    "\n",
    "La idea básica es que las muestras son partículas que partiendo de un punto inicial con una velocidad inicial, se deslizan a través de la distribución de probabilidad (siguiendo las ecuaciones de movimiento) para generar la siguiente muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sintonizar los parámetros $\\epsilon$ y $L$ puede resultar una tarea interesante, y de ellos depende la calidad de las muestras que obtenemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la práctica `pymc` hará todo el trabajo por nosotros. Ya están los métodos de HMC programados con la selección automática de los parámetros, que nos generarán, en la mayoría de los casos, muestras bastante competentes. El tipo de algoritmo que usa pymc por defecto es un NO-U-TURN SAMPLER o NUTS.\n",
    "\n",
    "Sin embargo, conviene entender un poco los conceptos detrás de estos algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
